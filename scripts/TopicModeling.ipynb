{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBHd6fhed6Sn",
        "outputId": "3a24a5df-5d3f-4a0e-dbb8-eb11a287413b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import nltk\n",
        "from gensim import corpora, models\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import itertools\n",
        "import string"
      ],
      "metadata": {
        "id": "biRECTE9rbxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLSZ2xkcsKnk",
        "outputId": "1b4d49e0-aa04-4f44-cb55-ce5981268abd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"drive/MyDrive/mooc_transcript_data/transcripts_txt/mooc1_textretrieval_txt\"\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "documents = []\n",
        "for filename in os.listdir(path):\n",
        "  if filename.endswith(\"txt\") and filename != \"textretrieval_alltranscripts.txt\":\n",
        "    with open(os.path.join(path, filename), 'r', encoding='utf8') as f:\n",
        "        text = f.read()\n",
        "        text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "        tokens = word_tokenize(text.lower())\n",
        "        tokens = [word for word in tokens if word not in stop_words and word!= \"sound\" and word!=\"music\"]\n",
        "        documents.append(tokens)\n",
        "\n",
        "dictionary = corpora.Dictionary(documents)\n",
        "corpus = [dictionary.doc2bow(doc) for doc in documents]\n",
        "\n"
      ],
      "metadata": {
        "id": "Shhthp50uJOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alpha = [0.1,0.01,'symmetric', 'asymmetric','auto']\n",
        "eta = [0.1,0.01,'auto','symmetric']\n",
        "num_topics = [5, 10, 20, 30, 50]\n",
        "\n",
        "# Define a function to train and evaluate the model for each combination of hyperparameters\n",
        "def train_and_evaluate_model(corpus, dictionary, num_topics, alpha, eta):\n",
        "    lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topics, alpha=alpha, eta=eta,passes = 25)\n",
        "    coherence_model = CoherenceModel(model=lda_model, corpus=corpus, coherence='u_mass')\n",
        "    coherence_score = coherence_model.get_coherence()\n",
        "    return lda_model, coherence_score\n",
        "\n",
        "# Create a list of all possible combinations of hyperparameters\n",
        "hyperparameter_combinations = list(itertools.product(alpha, eta, num_topics))\n",
        "\n",
        "# Train and evaluate the model for each combination of hyperparameters\n",
        "best_model = None\n",
        "best_score = -1\n",
        "for combination in hyperparameter_combinations:\n",
        "    alpha_val, eta_val, num_topics_val = combination\n",
        "    model, score = train_and_evaluate_model(corpus, dictionary, num_topics_val, alpha_val, eta_val)\n",
        "    print(f\"alpha={alpha_val}, eta={eta_val}, num_topics={num_topics_val}, coherence_score={score}\")\n",
        "    if score > best_score:\n",
        "        best_model = model\n",
        "        best_score = score\n",
        "\n",
        "# Print the best model and its coherence score\n",
        "print(\"Best model:\")\n",
        "print(best_model)\n",
        "print(\"Best coherence score:\", best_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5WTlNOcIJMc",
        "outputId": "15446615-3da2-497f-dde2-dccc97268e6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alpha=0.1, eta=0.1, num_topics=5, coherence_score=-0.43586005782426646\n",
            "alpha=0.1, eta=0.1, num_topics=10, coherence_score=-0.7142530129627385\n",
            "alpha=0.1, eta=0.1, num_topics=20, coherence_score=-0.6484125525887012\n",
            "alpha=0.1, eta=0.1, num_topics=30, coherence_score=-0.5600764577590576\n",
            "alpha=0.1, eta=0.01, num_topics=5, coherence_score=-0.4390669370383608\n",
            "alpha=0.1, eta=0.01, num_topics=10, coherence_score=-0.6280115076626449\n",
            "alpha=0.1, eta=0.01, num_topics=20, coherence_score=-0.5921751677061403\n",
            "alpha=0.1, eta=0.01, num_topics=30, coherence_score=-0.5265444965466073\n",
            "alpha=0.1, eta=auto, num_topics=5, coherence_score=-0.579703904117069\n",
            "alpha=0.1, eta=auto, num_topics=10, coherence_score=-0.8072496482808988\n",
            "alpha=0.1, eta=auto, num_topics=20, coherence_score=-0.7327712184854164\n",
            "alpha=0.1, eta=auto, num_topics=30, coherence_score=-0.5267857784161981\n",
            "alpha=0.1, eta=symmetric, num_topics=5, coherence_score=-0.4669718405032836\n",
            "alpha=0.1, eta=symmetric, num_topics=10, coherence_score=-0.70355871117108\n",
            "alpha=0.1, eta=symmetric, num_topics=20, coherence_score=-0.7234672981315647\n",
            "alpha=0.1, eta=symmetric, num_topics=30, coherence_score=-0.5121262439063679\n",
            "alpha=0.01, eta=0.1, num_topics=5, coherence_score=-0.3642166335699367\n",
            "alpha=0.01, eta=0.1, num_topics=10, coherence_score=-0.8011930517380641\n",
            "alpha=0.01, eta=0.1, num_topics=20, coherence_score=-0.6597317990610484\n",
            "alpha=0.01, eta=0.1, num_topics=30, coherence_score=-0.4980758323405007\n",
            "alpha=0.01, eta=0.01, num_topics=5, coherence_score=-0.4405280837189835\n",
            "alpha=0.01, eta=0.01, num_topics=10, coherence_score=-0.8886341040678939\n",
            "alpha=0.01, eta=0.01, num_topics=20, coherence_score=-0.560061717452796\n",
            "alpha=0.01, eta=0.01, num_topics=30, coherence_score=-0.5954349804633264\n",
            "alpha=0.01, eta=auto, num_topics=5, coherence_score=-0.534353127753819\n",
            "alpha=0.01, eta=auto, num_topics=10, coherence_score=-0.46874856134575066\n",
            "alpha=0.01, eta=auto, num_topics=20, coherence_score=-0.5873219847440179\n",
            "alpha=0.01, eta=auto, num_topics=30, coherence_score=-0.47905250985900705\n",
            "alpha=0.01, eta=symmetric, num_topics=5, coherence_score=-0.4567473669479507\n",
            "alpha=0.01, eta=symmetric, num_topics=10, coherence_score=-0.6528363859351478\n",
            "alpha=0.01, eta=symmetric, num_topics=20, coherence_score=-0.525466632083189\n",
            "alpha=0.01, eta=symmetric, num_topics=30, coherence_score=-0.5045290319629646\n",
            "alpha=symmetric, eta=0.1, num_topics=5, coherence_score=-0.5324847181124246\n",
            "alpha=symmetric, eta=0.1, num_topics=10, coherence_score=-0.6663547687539487\n",
            "alpha=symmetric, eta=0.1, num_topics=20, coherence_score=-0.6135496749678823\n",
            "alpha=symmetric, eta=0.1, num_topics=30, coherence_score=-0.670420440000208\n",
            "alpha=symmetric, eta=0.01, num_topics=5, coherence_score=-0.6959454208364854\n",
            "alpha=symmetric, eta=0.01, num_topics=10, coherence_score=-0.5873415282466878\n",
            "alpha=symmetric, eta=0.01, num_topics=20, coherence_score=-0.5070429352116513\n",
            "alpha=symmetric, eta=0.01, num_topics=30, coherence_score=-0.598079611534419\n",
            "alpha=symmetric, eta=auto, num_topics=5, coherence_score=-0.5735403782528077\n",
            "alpha=symmetric, eta=auto, num_topics=10, coherence_score=-0.699637123940276\n",
            "alpha=symmetric, eta=auto, num_topics=20, coherence_score=-0.6638318319852565\n",
            "alpha=symmetric, eta=auto, num_topics=30, coherence_score=-0.596386416301479\n",
            "alpha=symmetric, eta=symmetric, num_topics=5, coherence_score=-0.45271464528243516\n",
            "alpha=symmetric, eta=symmetric, num_topics=10, coherence_score=-0.5020251065037459\n",
            "alpha=symmetric, eta=symmetric, num_topics=20, coherence_score=-0.5838277166432728\n",
            "alpha=symmetric, eta=symmetric, num_topics=30, coherence_score=-0.6094819842255894\n",
            "alpha=asymmetric, eta=0.1, num_topics=5, coherence_score=-0.3960646714655017\n",
            "alpha=asymmetric, eta=0.1, num_topics=10, coherence_score=-0.67929210570646\n",
            "alpha=asymmetric, eta=0.1, num_topics=20, coherence_score=-0.5193946290558236\n",
            "alpha=asymmetric, eta=0.1, num_topics=30, coherence_score=-0.6038270755350749\n",
            "alpha=asymmetric, eta=0.01, num_topics=5, coherence_score=-0.5065003178268946\n",
            "alpha=asymmetric, eta=0.01, num_topics=10, coherence_score=-0.7298719709906155\n",
            "alpha=asymmetric, eta=0.01, num_topics=20, coherence_score=-0.6818121751448096\n",
            "alpha=asymmetric, eta=0.01, num_topics=30, coherence_score=-0.5037906384808392\n",
            "alpha=asymmetric, eta=auto, num_topics=5, coherence_score=-0.37895811463010615\n",
            "alpha=asymmetric, eta=auto, num_topics=10, coherence_score=-0.5752394806660973\n",
            "alpha=asymmetric, eta=auto, num_topics=20, coherence_score=-0.7193078914063569\n",
            "alpha=asymmetric, eta=auto, num_topics=30, coherence_score=-0.5106735238667816\n",
            "alpha=asymmetric, eta=symmetric, num_topics=5, coherence_score=-0.8120248172993447\n",
            "alpha=asymmetric, eta=symmetric, num_topics=10, coherence_score=-0.5971101453496466\n",
            "alpha=asymmetric, eta=symmetric, num_topics=20, coherence_score=-0.547879088019472\n",
            "alpha=asymmetric, eta=symmetric, num_topics=30, coherence_score=-0.4504021667835089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamodel:updated prior is not positive\n",
            "WARNING:gensim.models.ldamodel:updated prior is not positive\n",
            "WARNING:gensim.models.ldamodel:updated prior is not positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alpha=auto, eta=0.1, num_topics=5, coherence_score=-0.5774175408698772\n",
            "alpha=auto, eta=0.1, num_topics=10, coherence_score=-1.3887898149414681\n",
            "alpha=auto, eta=0.1, num_topics=20, coherence_score=-0.785721536551766\n",
            "alpha=auto, eta=0.1, num_topics=30, coherence_score=-0.5210501464464797\n",
            "alpha=auto, eta=0.01, num_topics=5, coherence_score=-0.5012480875969287\n",
            "alpha=auto, eta=0.01, num_topics=10, coherence_score=-0.5644962477231329\n",
            "alpha=auto, eta=0.01, num_topics=20, coherence_score=-0.5437404773607348\n",
            "alpha=auto, eta=0.01, num_topics=30, coherence_score=-0.5811656462350238\n",
            "alpha=auto, eta=auto, num_topics=5, coherence_score=-0.428075511851903\n",
            "alpha=auto, eta=auto, num_topics=10, coherence_score=-0.6589690641491475\n",
            "alpha=auto, eta=auto, num_topics=20, coherence_score=-0.6687025783639463\n",
            "alpha=auto, eta=auto, num_topics=30, coherence_score=-0.5093687025733418\n",
            "alpha=auto, eta=symmetric, num_topics=5, coherence_score=-0.41238264597193897\n",
            "alpha=auto, eta=symmetric, num_topics=10, coherence_score=-0.4746952966088648\n",
            "alpha=auto, eta=symmetric, num_topics=20, coherence_score=-0.5839303611034867\n",
            "alpha=auto, eta=symmetric, num_topics=30, coherence_score=-0.4956555589930386\n",
            "Best model:\n",
            "LdaModel<num_terms=3270, num_topics=5, decay=0.5, chunksize=2000>\n",
            "Best coherence score: -0.3642166335699367\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lda_model = models.LdaModel(corpus=corpus, id2word=dictionary, num_topics=5, passes = 10, eta =0.1,alpha=0.01)\n",
        "for idx, doc_bow in enumerate(corpus):\n",
        "    doc_topics = lda_model.get_document_topics(doc_bow)\n",
        "    top_topics = sorted(doc_topics, key=lambda x: x[1], reverse=True)\n",
        "    for topic_id, prob in top_topics:\n",
        "        print(f'Document : {idx} -->\\tTopic {topic_id}: {prob:.3f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sxj5yKuQHtOj",
        "outputId": "5a45fda6-63ca-43be-ab37-ac4d0a51847f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document : 0 -->\tTopic 3: 1.000\n",
            "Document : 1 -->\tTopic 3: 1.000\n",
            "Document : 2 -->\tTopic 1: 0.778\n",
            "Document : 2 -->\tTopic 4: 0.222\n",
            "Document : 3 -->\tTopic 0: 0.535\n",
            "Document : 3 -->\tTopic 4: 0.434\n",
            "Document : 3 -->\tTopic 3: 0.031\n",
            "Document : 4 -->\tTopic 3: 1.000\n",
            "Document : 5 -->\tTopic 0: 0.787\n",
            "Document : 5 -->\tTopic 3: 0.213\n",
            "Document : 6 -->\tTopic 4: 1.000\n",
            "Document : 7 -->\tTopic 2: 1.000\n",
            "Document : 8 -->\tTopic 4: 0.945\n",
            "Document : 8 -->\tTopic 3: 0.055\n",
            "Document : 9 -->\tTopic 4: 1.000\n",
            "Document : 10 -->\tTopic 4: 1.000\n",
            "Document : 11 -->\tTopic 4: 1.000\n",
            "Document : 12 -->\tTopic 4: 0.918\n",
            "Document : 12 -->\tTopic 3: 0.048\n",
            "Document : 12 -->\tTopic 0: 0.034\n",
            "Document : 13 -->\tTopic 4: 1.000\n",
            "Document : 14 -->\tTopic 0: 1.000\n",
            "Document : 15 -->\tTopic 0: 1.000\n",
            "Document : 16 -->\tTopic 0: 1.000\n",
            "Document : 17 -->\tTopic 0: 0.552\n",
            "Document : 17 -->\tTopic 3: 0.448\n",
            "Document : 18 -->\tTopic 0: 1.000\n",
            "Document : 19 -->\tTopic 1: 0.865\n",
            "Document : 19 -->\tTopic 0: 0.135\n",
            "Document : 20 -->\tTopic 4: 1.000\n",
            "Document : 21 -->\tTopic 4: 1.000\n",
            "Document : 22 -->\tTopic 4: 0.571\n",
            "Document : 22 -->\tTopic 0: 0.429\n",
            "Document : 23 -->\tTopic 4: 1.000\n",
            "Document : 24 -->\tTopic 4: 1.000\n",
            "Document : 25 -->\tTopic 0: 0.912\n",
            "Document : 25 -->\tTopic 4: 0.088\n",
            "Document : 26 -->\tTopic 4: 1.000\n",
            "Document : 27 -->\tTopic 4: 0.967\n",
            "Document : 27 -->\tTopic 0: 0.033\n",
            "Document : 28 -->\tTopic 4: 1.000\n",
            "Document : 29 -->\tTopic 4: 1.000\n",
            "Document : 30 -->\tTopic 2: 1.000\n",
            "Document : 31 -->\tTopic 0: 0.985\n",
            "Document : 31 -->\tTopic 2: 0.015\n",
            "Document : 32 -->\tTopic 2: 1.000\n",
            "Document : 33 -->\tTopic 3: 0.992\n",
            "Document : 34 -->\tTopic 0: 1.000\n",
            "Document : 35 -->\tTopic 1: 1.000\n",
            "Document : 36 -->\tTopic 0: 0.988\n",
            "Document : 36 -->\tTopic 4: 0.012\n",
            "Document : 37 -->\tTopic 2: 0.636\n",
            "Document : 37 -->\tTopic 0: 0.292\n",
            "Document : 37 -->\tTopic 3: 0.073\n",
            "Document : 38 -->\tTopic 3: 1.000\n",
            "Document : 39 -->\tTopic 0: 0.746\n",
            "Document : 39 -->\tTopic 2: 0.212\n",
            "Document : 39 -->\tTopic 3: 0.042\n",
            "Document : 40 -->\tTopic 2: 0.953\n",
            "Document : 40 -->\tTopic 0: 0.047\n",
            "Document : 41 -->\tTopic 3: 0.967\n",
            "Document : 41 -->\tTopic 4: 0.027\n",
            "Document : 42 -->\tTopic 2: 1.000\n",
            "Document : 43 -->\tTopic 2: 1.000\n",
            "Document : 44 -->\tTopic 3: 0.783\n",
            "Document : 44 -->\tTopic 2: 0.162\n",
            "Document : 44 -->\tTopic 0: 0.054\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for topic_id, topic in lda_model.print_topics(num_topics=5):\n",
        "    print(f\"Topic {topic_id}\\n {topic}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkTeeaBjfQ7y",
        "outputId": "186274fc-bcf4-4112-c618-b6cde024d01d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 0\n",
            " 0.021*\"text\" + 0.017*\"search\" + 0.015*\"information\" + 0.015*\"data\" + 0.012*\"would\" + 0.011*\"words\" + 0.010*\"also\" + 0.009*\"well\" + 0.009*\"language\" + 0.008*\"example\"\n",
            "Topic 1\n",
            " 0.022*\"query\" + 0.021*\"probability\" + 0.017*\"user\" + 0.016*\"document\" + 0.014*\"model\" + 0.012*\"documents\" + 0.012*\"function\" + 0.011*\"features\" + 0.010*\"retrieval\" + 0.009*\"also\"\n",
            "Topic 2\n",
            " 0.014*\"index\" + 0.014*\"page\" + 0.013*\"web\" + 0.013*\"pages\" + 0.013*\"also\" + 0.012*\"search\" + 0.011*\"would\" + 0.011*\"term\" + 0.010*\"right\" + 0.009*\"documents\"\n",
            "Topic 3\n",
            " 0.015*\"would\" + 0.013*\"function\" + 0.013*\"probability\" + 0.011*\"see\" + 0.011*\"right\" + 0.009*\"user\" + 0.009*\"one\" + 0.009*\"page\" + 0.009*\"values\" + 0.008*\"also\"\n",
            "Topic 4\n",
            " 0.019*\"document\" + 0.017*\"documents\" + 0.016*\"query\" + 0.015*\"would\" + 0.012*\"model\" + 0.011*\"one\" + 0.010*\"see\" + 0.009*\"words\" + 0.009*\"also\" + 0.009*\"well\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lda_model = models.LdaModel(corpus=corpus, id2word=dictionary, num_topics=30, passes = 10, eta ='symmetric',alpha='asymmetric')\n",
        "for topic_id, topic in lda_model.print_topics(num_topics=30):\n",
        "    print(f\"Topic {topic_id}: {topic}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydpwO6QeaGv7",
        "outputId": "b15f9daf-2049-4e6d-d97f-fe5a592b969f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 0: 0.001*\"would\" + 0.001*\"document\" + 0.001*\"documents\" + 0.001*\"query\" + 0.001*\"see\" + 0.001*\"one\" + 0.001*\"model\" + 0.001*\"right\" + 0.001*\"two\" + 0.001*\"also\"\n",
            "Topic 1: 0.033*\"document\" + 0.027*\"score\" + 0.025*\"query\" + 0.024*\"function\" + 0.021*\"term\" + 0.017*\"models\" + 0.014*\"inverted\" + 0.013*\"index\" + 0.013*\"information\" + 0.013*\"retrieval\"\n",
            "Topic 2: 0.034*\"pseudocount\" + 0.012*\"network\" + 0.012*\"dynamic\" + 0.007*\"coefficients\" + 0.007*\"front\" + 0.007*\"mercer\" + 0.007*\"normalized\" + 0.007*\"counters\" + 0.007*\"smallest\" + 0.007*\"ms\"\n",
            "Topic 3: 0.020*\"system\" + 0.019*\"user\" + 0.015*\"would\" + 0.015*\"search\" + 0.013*\"users\" + 0.012*\"threshold\" + 0.011*\"utility\" + 0.011*\"text\" + 0.010*\"one\" + 0.010*\"talked\"\n",
            "Topic 4: 0.001*\"document\" + 0.001*\"would\" + 0.001*\"model\" + 0.001*\"probability\" + 0.001*\"word\" + 0.001*\"query\" + 0.000*\"also\" + 0.000*\"one\" + 0.000*\"see\" + 0.000*\"documents\"\n",
            "Topic 5: 0.055*\"features\" + 0.027*\"ranking\" + 0.025*\"function\" + 0.020*\"training\" + 0.019*\"combine\" + 0.017*\"generate\" + 0.015*\"page\" + 0.015*\"question\" + 0.014*\"data\" + 0.013*\"parameters\"\n",
            "Topic 6: 0.038*\"page\" + 0.029*\"probability\" + 0.022*\"random\" + 0.017*\"would\" + 0.016*\"surfer\" + 0.015*\"one\" + 0.015*\"server\" + 0.014*\"metrics\" + 0.013*\"scores\" + 0.013*\"see\"\n",
            "Topic 7: 0.042*\"user\" + 0.030*\"users\" + 0.024*\"ratings\" + 0.018*\"filtering\" + 0.016*\"items\" + 0.014*\"would\" + 0.013*\"similarity\" + 0.013*\"similar\" + 0.012*\"rating\" + 0.011*\"well\"\n",
            "Topic 8: 0.023*\"documents\" + 0.015*\"document\" + 0.015*\"would\" + 0.014*\"one\" + 0.012*\"vector\" + 0.011*\"query\" + 0.009*\"well\" + 0.009*\"see\" + 0.009*\"right\" + 0.008*\"also\"\n",
            "Topic 9: 0.050*\"data\" + 0.038*\"text\" + 0.021*\"search\" + 0.019*\"course\" + 0.019*\"systems\" + 0.013*\"also\" + 0.011*\"useful\" + 0.011*\"mining\" + 0.009*\"engines\" + 0.009*\"cover\"\n",
            "Topic 10: 0.018*\"would\" + 0.014*\"one\" + 0.013*\"function\" + 0.013*\"key\" + 0.012*\"average\" + 0.012*\"think\" + 0.012*\"different\" + 0.011*\"map\" + 0.009*\"right\" + 0.009*\"difference\"\n",
            "Topic 11: 0.001*\"would\" + 0.001*\"one\" + 0.001*\"right\" + 0.001*\"documents\" + 0.001*\"well\" + 0.001*\"also\" + 0.001*\"use\" + 0.001*\"words\" + 0.001*\"example\" + 0.001*\"function\"\n",
            "Topic 12: 0.021*\"documents\" + 0.020*\"query\" + 0.020*\"document\" + 0.012*\"would\" + 0.012*\"also\" + 0.011*\"user\" + 0.011*\"see\" + 0.011*\"words\" + 0.010*\"probability\" + 0.010*\"model\"\n",
            "Topic 13: 0.019*\"document\" + 0.017*\"function\" + 0.013*\"would\" + 0.012*\"documents\" + 0.012*\"see\" + 0.011*\"one\" + 0.010*\"also\" + 0.010*\"term\" + 0.009*\"query\" + 0.009*\"vector\"\n",
            "Topic 14: 0.045*\"information\" + 0.028*\"search\" + 0.016*\"system\" + 0.016*\"users\" + 0.013*\"support\" + 0.013*\"need\" + 0.013*\"user\" + 0.012*\"browsing\" + 0.011*\"would\" + 0.010*\"access\"\n",
            "Topic 15: 0.002*\"would\" + 0.002*\"vector\" + 0.002*\"also\" + 0.002*\"pages\" + 0.001*\"good\" + 0.001*\"text\" + 0.001*\"one\" + 0.001*\"right\" + 0.001*\"scores\" + 0.001*\"authority\"\n",
            "Topic 16: 0.001*\"document\" + 0.001*\"would\" + 0.001*\"model\" + 0.001*\"query\" + 0.001*\"documents\" + 0.001*\"one\" + 0.001*\"also\" + 0.001*\"word\" + 0.001*\"term\" + 0.001*\"see\"\n",
            "Topic 17: 0.030*\"page\" + 0.024*\"web\" + 0.024*\"pages\" + 0.017*\"search\" + 0.013*\"also\" + 0.011*\"right\" + 0.011*\"link\" + 0.011*\"links\" + 0.010*\"many\" + 0.010*\"information\"\n",
            "Topic 18: 0.001*\"function\" + 0.001*\"would\" + 0.001*\"users\" + 0.001*\"user\" + 0.001*\"filtering\" + 0.001*\"document\" + 0.001*\"see\" + 0.001*\"well\" + 0.001*\"information\" + 0.001*\"values\"\n",
            "Topic 19: 0.032*\"model\" + 0.028*\"words\" + 0.027*\"query\" + 0.025*\"document\" + 0.022*\"probability\" + 0.020*\"word\" + 0.018*\"would\" + 0.013*\"vector\" + 0.013*\"sum\" + 0.013*\"language\"\n",
            "Topic 20: 0.001*\"document\" + 0.001*\"would\" + 0.001*\"one\" + 0.001*\"documents\" + 0.001*\"see\" + 0.001*\"well\" + 0.001*\"also\" + 0.001*\"right\" + 0.001*\"query\" + 0.001*\"average\"\n",
            "Topic 21: 0.030*\"good\" + 0.028*\"hub\" + 0.024*\"scores\" + 0.022*\"authority\" + 0.022*\"pages\" + 0.018*\"also\" + 0.018*\"matrix\" + 0.016*\"would\" + 0.016*\"authorities\" + 0.016*\"equation\"\n",
            "Topic 22: 0.030*\"code\" + 0.018*\"document\" + 0.015*\"use\" + 0.015*\"bits\" + 0.015*\"would\" + 0.014*\"ids\" + 0.013*\"unary\" + 0.013*\"x\" + 0.012*\"coding\" + 0.012*\"see\"\n",
            "Topic 23: 0.008*\"jelinek\" + 0.008*\"bayesian\" + 0.008*\"mixing\" + 0.008*\"james\" + 0.008*\"normalizes\" + 0.002*\"probability\" + 0.002*\"see\" + 0.001*\"network\" + 0.001*\"document\" + 0.001*\"words\"\n",
            "Topic 24: 0.019*\"sentence\" + 0.016*\"would\" + 0.015*\"natural\" + 0.015*\"language\" + 0.013*\"words\" + 0.013*\"example\" + 0.013*\"text\" + 0.011*\"also\" + 0.010*\"understanding\" + 0.010*\"data\"\n",
            "Topic 25: 0.001*\"document\" + 0.001*\"query\" + 0.001*\"would\" + 0.001*\"words\" + 0.001*\"also\" + 0.001*\"one\" + 0.001*\"function\" + 0.001*\"word\" + 0.001*\"documents\" + 0.001*\"well\"\n",
            "Topic 26: 0.001*\"would\" + 0.001*\"user\" + 0.001*\"documents\" + 0.001*\"text\" + 0.001*\"search\" + 0.001*\"also\" + 0.001*\"use\" + 0.001*\"see\" + 0.001*\"well\" + 0.001*\"data\"\n",
            "Topic 27: 0.001*\"would\" + 0.001*\"one\" + 0.001*\"probability\" + 0.001*\"words\" + 0.001*\"also\" + 0.001*\"see\" + 0.001*\"text\" + 0.000*\"well\" + 0.000*\"model\" + 0.000*\"data\"\n",
            "Topic 28: 0.087*\"recall\" + 0.082*\"precision\" + 0.051*\"relevant\" + 0.028*\"measures\" + 0.023*\"measure\" + 0.021*\"system\" + 0.021*\"documents\" + 0.021*\"results\" + 0.017*\"case\" + 0.016*\"b\"\n",
            "Topic 29: 0.044*\"model\" + 0.033*\"feedback\" + 0.026*\"query\" + 0.021*\"words\" + 0.019*\"documents\" + 0.015*\"use\" + 0.015*\"user\" + 0.013*\"going\" + 0.013*\"language\" + 0.013*\"would\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, doc_bow in enumerate(corpus):\n",
        "    doc_topics = lda_model.get_document_topics(doc_bow)\n",
        "    top_topics = sorted(doc_topics, key=lambda x: x[1], reverse=True)\n",
        "    for topic_id, prob in top_topics:\n",
        "        print(f'Document : {idx} -->\\tTopic {topic_id}: {prob:.3f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApCcb87NkInr",
        "outputId": "d6f1b4b5-2817-46a7-a837-cbad064a864c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document : 0 -->\tTopic 9: 0.996\n",
            "Document : 1 -->\tTopic 9: 0.921\n",
            "Document : 1 -->\tTopic 14: 0.052\n",
            "Document : 1 -->\tTopic 12: 0.026\n",
            "Document : 2 -->\tTopic 8: 0.591\n",
            "Document : 2 -->\tTopic 19: 0.407\n",
            "Document : 3 -->\tTopic 12: 0.796\n",
            "Document : 3 -->\tTopic 3: 0.147\n",
            "Document : 3 -->\tTopic 17: 0.030\n",
            "Document : 4 -->\tTopic 24: 0.999\n",
            "Document : 5 -->\tTopic 14: 0.999\n",
            "Document : 6 -->\tTopic 1: 0.985\n",
            "Document : 6 -->\tTopic 19: 0.014\n",
            "Document : 7 -->\tTopic 22: 0.991\n",
            "Document : 8 -->\tTopic 8: 0.535\n",
            "Document : 8 -->\tTopic 1: 0.444\n",
            "Document : 8 -->\tTopic 10: 0.018\n",
            "Document : 9 -->\tTopic 19: 0.946\n",
            "Document : 9 -->\tTopic 13: 0.053\n",
            "Document : 10 -->\tTopic 8: 0.802\n",
            "Document : 10 -->\tTopic 19: 0.197\n",
            "Document : 11 -->\tTopic 13: 0.996\n",
            "Document : 12 -->\tTopic 12: 0.999\n",
            "Document : 13 -->\tTopic 13: 0.999\n",
            "Document : 14 -->\tTopic 3: 0.728\n",
            "Document : 14 -->\tTopic 8: 0.154\n",
            "Document : 14 -->\tTopic 13: 0.116\n",
            "Document : 15 -->\tTopic 28: 0.328\n",
            "Document : 15 -->\tTopic 8: 0.289\n",
            "Document : 15 -->\tTopic 13: 0.178\n",
            "Document : 16 -->\tTopic 8: 0.687\n",
            "Document : 16 -->\tTopic 10: 0.232\n",
            "Document : 16 -->\tTopic 28: 0.076\n",
            "Document : 17 -->\tTopic 8: 0.685\n",
            "Document : 17 -->\tTopic 3: 0.214\n",
            "Document : 17 -->\tTopic 12: 0.100\n",
            "Document : 18 -->\tTopic 8: 0.999\n",
            "Document : 19 -->\tTopic 10: 0.991\n",
            "Document : 20 -->\tTopic 12: 0.785\n",
            "Document : 20 -->\tTopic 19: 0.214\n",
            "Document : 21 -->\tTopic 19: 0.999\n",
            "Document : 22 -->\tTopic 12: 0.953\n",
            "Document : 22 -->\tTopic 19: 0.046\n",
            "Document : 23 -->\tTopic 19: 0.948\n",
            "Document : 23 -->\tTopic 12: 0.031\n",
            "Document : 23 -->\tTopic 9: 0.020\n",
            "Document : 24 -->\tTopic 19: 0.828\n",
            "Document : 24 -->\tTopic 13: 0.171\n",
            "Document : 25 -->\tTopic 29: 0.998\n",
            "Document : 26 -->\tTopic 29: 0.859\n",
            "Document : 26 -->\tTopic 19: 0.141\n",
            "Document : 27 -->\tTopic 8: 0.964\n",
            "Document : 27 -->\tTopic 29: 0.035\n",
            "Document : 28 -->\tTopic 12: 0.917\n",
            "Document : 28 -->\tTopic 19: 0.082\n",
            "Document : 29 -->\tTopic 19: 0.908\n",
            "Document : 29 -->\tTopic 12: 0.052\n",
            "Document : 29 -->\tTopic 2: 0.030\n",
            "Document : 30 -->\tTopic 21: 0.997\n",
            "Document : 31 -->\tTopic 17: 0.998\n",
            "Document : 32 -->\tTopic 6: 0.750\n",
            "Document : 32 -->\tTopic 17: 0.249\n",
            "Document : 33 -->\tTopic 10: 0.999\n",
            "Document : 34 -->\tTopic 17: 0.984\n",
            "Document : 35 -->\tTopic 13: 0.989\n",
            "Document : 36 -->\tTopic 5: 0.504\n",
            "Document : 36 -->\tTopic 13: 0.333\n",
            "Document : 36 -->\tTopic 3: 0.085\n",
            "Document : 37 -->\tTopic 13: 0.779\n",
            "Document : 37 -->\tTopic 3: 0.183\n",
            "Document : 37 -->\tTopic 9: 0.035\n",
            "Document : 38 -->\tTopic 14: 0.759\n",
            "Document : 38 -->\tTopic 3: 0.097\n",
            "Document : 38 -->\tTopic 24: 0.054\n",
            "Document : 39 -->\tTopic 3: 0.999\n",
            "Document : 40 -->\tTopic 3: 0.999\n",
            "Document : 41 -->\tTopic 3: 0.978\n",
            "Document : 41 -->\tTopic 9: 0.021\n",
            "Document : 42 -->\tTopic 7: 0.505\n",
            "Document : 42 -->\tTopic 8: 0.492\n",
            "Document : 43 -->\tTopic 7: 0.999\n",
            "Document : 44 -->\tTopic 7: 0.956\n",
            "Document : 44 -->\tTopic 14: 0.041\n"
          ]
        }
      ]
    }
  ]
}