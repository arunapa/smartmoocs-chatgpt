{
	"summaries": {
        "Lesson 0.1": {"00:00:00": "\"Course on Text Retrieval and Search Engines, covers objectives, pre-requisites, format, books, and schedule.\"", "00:01:01": "UIUC offers 5 courses and a capstone project on data mining, including general and text techniques.", "00:02:03": "\"Learn to extract insights from big text data including web pages, news articles, and tweets.\""},
        "Lesson 0.2": {"00:00:00": "Text has useful data for AI, but it's hard to process.", "00:01:00": "AI tools aid text analysis, need human interaction, encompass search engines and research aids.", "00:02:00": "Information systems include search, filter, recommend, and categorize. They require binary decisions and organize information.", "00:03:02": "Text analysis finds insights in text for better productivity and customer relations.", "00:04:02": "Text mining discovers insights and gives a competitive edge using valuable information from text.", "00:05:02": "Text retrieval finds data, text mining extracts insights. Separate processes with different purposes.", "00:06:05": "Text Mining and Analytics course teaches techniques in text retrieval, search engine implementation, and evaluation.", "00:07:08": "Fundamentals and programming for search engines with quizzes, assignments, and competition. Reference books provided.", "00:08:10": "Text information systems course - natural language analysis & understanding large volumes of text data.", "00:09:11": "Search engines and recommender systems help users find relevant data through querying and pushing information."},
        "Lesson 1.1": {"00:00:00": "Intro to content analysis for processing text data, related to NLP and text retrieval.", "00:01:00": "Computers require lexile and part-of-speech analysis for understanding foreign language sentence structure.", "00:02:00": "Understanding sentence structure uses syntax, semantics, parsers and symbols for analysis.", "00:03:01": "Computers use symbols to represent language and make connections through inference, understanding meaning behind words.", "00:04:02": "Pragmatic analysis deals with language's purpose. Computers find it challenging to understand natural language.", "00:05:06": "Computers struggle with natural language processing due to lack of knowledge and ambiguity.", "00:06:10": "Natural language processing is difficult due to ambiguity, which includes word and syntactical ambiguities.", "00:07:15": "Ambiguous syntax and anaphora make understanding meaning difficult, but context and knowledge aid comprehension.", "00:08:15": "Computers struggle with natural language due to large knowledge base, with only accurate part-of-speech tagging.", "00:09:15": "Computers can partially parse sentences with about 90% accuracy, but complete understanding is lacking.", "00:10:16": "NLP extracts entities and relations from text. Results vary based on context and mention difficulty.", "00:11:19": "Semantic analysis provides partial understanding, but inference is a challenge due to natural language complexity.", "00:12:21": "Despite advances, NLP struggles with sarcasm, context and complex syntax, requiring further development.", "00:13:21": "Natural language is hard for computers, shallow analysis makes it difficult to understand complex sentences.", "00:14:25": "Natural language processing categorized as shallow or deep understanding, with limitations and advancements.", "00:15:29": "Text retrieval uses NLP techniques, but mainly relies on simple methods due to vast data.", "00:16:29": "Bag of words = no word order, for search not translation, used by major engines.", "00:17:32": "Search engines use bag of words, but techniques like word sense disambiguation solve NLP problems.", "00:18:35": "Retrieval techniques disambiguate words while feedback adds related words to improve relevance matching.", "00:19:35": "NLP helps machines learn human language, where deep NLP is crucial for complex tasks."},
        "Lesson 1.2": {"00:00:08": "Strategies to convert raw text into relevant data for text access through push and pull.", "00:01:12": "Push and pull modes connect users with information; pull mode involves querying or browsing searches.", "00:02:14": "User-initiated and search engines for ad hoc needs; system recommendation for stable needs.", "00:03:17": "System recommends relevant content by learning user preferences for news filters, recommenders, and search engines.", "00:04:17": "Text access has pull mode for querying with keywords and browsing for exploration.", "00:05:21": "Browsing is useful for exploring information when users can't determine keywords and for mobile users.", "00:06:21": "Searching for information is like sightseeing; using precise keywords is fastest, browsing takes time.", "00:07:24": "Advocating better browsing support, using sightseeing analogy, discussing push and pull text access."},
        "Lesson 1.3": {"00:00:00": "Comparison of text and database retrieval, and document selection and ranking importance.", "00:01:02": "Text retrieval finds relevant information for user queries from a collection of text documents.", "00:02:04": "Retrieving relevant information from user input, primarily through text, known as search technology.", "00:03:11": "Differentiating between text and database retrieval systems and their unique features is crucial.", "00:04:11": "Structured data is defined while unstructured data is ambiguous, making queries difficult.", "00:05:12": "Text retrieval searches for relevant documents, while database searches retrieve matched records with SQL.", "00:06:15": "Evaluation of text retrieval is empirical, crucial, and requires user feedback to improve search algorithms.", "00:07:17": "One language makes text retrieval easier, but methods for multiple languages are similar.", "00:08:21": "Words used to retrieve info from collections are queries and documents.", "00:09:29": "Text retrieval finds relevant documents from a large unknown collection, often for web search.", "00:10:29": "Search system finds relevant documents for user query from document collection using program.", "00:11:33": "Document selection and binary classification are two information retrieval strategies based on document relevance.", "00:12:33": "The relevant document set contains documents with a value of 1 based on relevance.", "00:13:37": "Search engine strategies: absolute relevance vs. document ranking using real value function for relevance assessment.", "00:14:46": "User-set threshold for ranking relevant docs is easier than absolute relevance.", "00:15:48": "Precision retrieves relevant, while recall retrieves some irrelevant documents along with relevant ones.", "00:16:49": "Ranking documents by score preferred over limited accuracy classifier for user selection.", "00:17:53": "Balanced queries produce accurate results, while constrained or under-constrained ones lead to irrelevant data.", "00:18:56": "Difficulty in balance results in irrelevant document delivery, providing too much information.", "00:19:57": "Ranking is crucial in information retrieval as users browse results sequentially based on probability.", "00:21:00": "Search engines assume equal relevance and importance, but document evaluation may vary.", "00:22:02": "Document relevance can depend on other documents seen, making duplicates less useful and combinations valuable.", "00:23:04": "Limitations of probability ranking principle but still basis for information retrieval in search engines.", "00:24:06": "Text retrieval requires user judgement; document ranking preferred; effective ranking function design a challenge.", "00:25:10": "Designing a function to determine the value of a query and document pair in IR."},
        "Lesson 1.4": {"00:00:00": "Overview of text retrieval methods, focusing on designing a ranking function to rank relevant documents.", "00:01:00": "Retrieval models determine a document's relevance to a query based on similarity. Many models exist.", "00:02:02": "Ranking functions determine similarity in information retrieval, using vector space and probabilistic models.", "00:03:04": "Four models of information retrieval seek to quantify uncertainty and define constraints for good function.", "00:04:06": "Different retrieval models use bag of words and similar variables to score documents for queries.", "00:05:09": "Search engine relevance based on term frequency & document length.", "00:06:12": "Document length and frequency of terms determine their significance and popularity in a collection.", "00:07:13": "Search engine models score based on term frequency, with BM25 being the most commonly used.", "00:08:13": "Effective ranking functions use a retrieval model with bag-of-words and TF-IDF methods."},
        "Lesson 1.5": {"00:00:00": "Introduction to vector space retrieval model: relevance measured by similarity between query and document.", "00:01:06": "Defining relevance is crucial for solving search problems; similar documents assumed more relevant, ranked accordingly.", "00:02:11": "Documents represented as vectors in a 3D space, allowing focus on relevant information, ignoring irrelevant.", "00:03:14": "Vector space representation captures topics in documents, ignoring word order; vectors represent difference and combinations.", "00:04:18": "The vector space model represents documents and queries as term vectors to retrieve relevant information.", "00:05:21": "Enneagrams, weight, and similarity define N-dimensional space for vectors in search queries and documents.", "00:06:26": "Need improvement in framework for search engine due to vague definition and selection.", "00:07:32": "Orthogonal concepts in IR avoid redundancy, document/query vector undefined, emphasize term weight.", "00:08:33": "Next lecture covers term weight, similarity measures, and implementation in programming language."},
        "Lesson 1.6": {"00:00:00": "Lecture explains using vector space model for ranking function instantiation, following framework guidance.", "00:01:00": "Vector space model framework lacks definitions and placements; requires careful consideration for implementation.", "00:02:02": "Vector space model: define concepts, weight, calculate similarity, and rank.", "00:03:03": "Similarity function uses Bag of Words to represent words as dimensions in vector space model.", "00:04:04": "Documents and queries are vectors that represent words with presence or absence in a vocabulary.", "00:05:11": "Dot product measures similarity between vectors; defined by the sum of corresponding element products.", "00:06:13": "VSM ranks documents based on words, dot product and bit vectors in bag-of-words model.", "00:07:15": "Consider function relevance and performance before using ranking in a query. Evaluate effectiveness.", "00:08:17": "Rank sample documents by relevance to presidential campaign query, d4 and d3 most relevant.", "00:09:19": "Two documents relevant to query, three non-relevant. Vector Space Model scores based on query vocabulary.", "00:10:19": "Binary bit vectors represent queries and documents, and similarity is computed using the dot product.", "00:11:19": "Dot product counts pairs of corresponding non-zero elements in vectors.", "00:12:20": "Matching function scores document based on unique query terms present. Demonstrated by example.", "00:13:21": "Ranking based on matched query terms can lead to difficulty in ranking when documents tie.", "00:14:25": "Keyword weighting in search results may inaccurately rank documents with more mentions of keywords lower.", "00:15:30": "Implementing a vector space model with defined dimensions and similarity for documents and queries."},
        "Lesson 2.1": {"00:00:00": "Lecture on improving Vector Space Model's scoring function by considering relevance of matched terms.", "00:01:00": "Current search engine scoring based on word frequency is flawed; relevance must be considered.", "00:02:04": "Reconsider term frequency to address problems in Vector Space Model's assumptions for vector placement.", "00:03:07": "Counting term frequency improves document representation for accurate analysis and calculating term importance.", "00:04:10": "New formula for document scoring considers multiple word occurrences and addresses Vector Space Model problem.", "00:05:12": "Changing to term frequency vectors affects scores in search engines. Increasing frequency increases score.", "00:06:14": "Problem: default search engine ranking favors \"stock words.\" Solution: ignore irrelevant words for better results.", "00:07:14": "Distinguishing words in NLP is challenging. Using global statistics can differentiate between presidential and about.", "00:08:15": "IDF boosts rare terms and reduces common terms' importance in text analysis.", "00:09:15": "Inverse document frequency rewards rare words and penalizes common ones based on document frequency.", "00:10:15": "Penalizes popular search terms, values rare words. Linear kernalization discussed.", "00:11:20": "TF-IDF measures word importance, but IDF may need adjustment for frequent words.", "00:12:26": "IDF weighting adjusts word importance in information retrieval, solving problems based on data and feedback.", "00:13:28": "IDF weighting improves text search engine rankings by considering the rarity of words in documents.", "00:14:28": "New ranking and scoring function have mixed results, highlighting challenges in design.", "00:15:33": "TF-IDF weighting improves vector space model, but limitations remain."},
        "Lesson 2.2": {"00:00:00": "TF-IDF weighting formula problematic, highest score given to non-relevant document. Solution needed.", "00:01:00": "Lecture explains using TF transformation to solve a problem, no details in text.", "00:02:07": "IDF ranks query terms by frequency, document count, and query word count for weight assessment.", "00:03:09": "Reduce high document score by limiting term frequency, first occurrence is more important.", "00:04:12": "TF Transformation counts word frequency, adjusts for high-frequency terms, and aids natural language processing.", "00:05:18": "Transform raw word count to term frequency using sub-linear method, BM25 works best.", "00:06:22": "A function with bounded output, simulating various transformations by varying k.", "00:07:24": "TF transformation controls shape of transformation, sub-linearity needed to capture diminishing returns.", "00:08:24": "BM25 Transformation formula helps avoid term dominance and improves ranking in information retrieval systems."},
        "Lesson 2.3": {"00:00:08": "This lecture explains the importance of document length normalization in the vector space model.", "00:01:10": "Large documents pose challenges for relevant information retrieval; \"document answer\" may penalize irrelevant content.", "00:02:12": "Penalizing long documents is okay, but overdoing it may harm legitimate research papers.", "00:03:13": "Length affects relevance score, penalize concatenated abstracts with pivot length normalization.", "00:04:14": "Document length normalization important in information retrieval, normalizer interpolated from 1 to average length.", "00:05:20": "BM25's \"b\" parameter controls length normalization, while \"d\" penalizes longer documents.", "00:06:20": "Variable b adjusts length normalization in vector space model ranking functions.", "00:07:24": "TF-IDF and BM25 score document relevance based on term frequency and additional factors.", "00:08:33": "Normalizing term frequencies adjusts weights and improves document placement in vector space.", "00:09:35": "Stemmed words, stopping words, and semantic clustering enhance the vector space model.", "00:10:39": "Text dimension can use bag-of-words or smaller units, but segmentation may be needed for Chinese.", "00:11:44": "Article suggests dot product as a method to determine word boundaries in spaceless languages.", "00:12:45": "Cosine measure linked to field-based BM25 and BM25 F ranking formulas for improved results.", "00:13:45": "BM25F improves document scoring by combining scores from each field to prevent over-counting.", "00:14:48": "Vector Space Model involves representing documents and queries as vectors; BM25 algorithm over-penalizes long documents.", "00:15:51": "Text and queries ranked using TF-IDF and normalization heuristics in vector space.", "00:16:51": "BM25 and Pivoted normalization are the most effective formulas in the Space Model."},
        "Lesson 2.4": {"00:00:00": "Search engines use tokenization, indexing, and query processing to manage large data in text retrieval.", "00:01:02": "System has tokenizer, scorer, and results; user feedback improves ranking accuracy.", "00:02:05": "An information retrieval system has indexer, scorer, and feedback mechanism, with varying implementation methods.", "00:03:09": "Tokenization normalizes words; stemming maps inflections to root form. Stemming can improve document matching.", "00:04:13": "Languages without spaces, like Chinese, require specific NLP techniques for tokenizing text for search indexing.", "00:05:13": "Feedback is crucial for ML models, inverted index helps pre-process text data for better response.", "00:06:15": "Inverted index helps find matching documents quickly by maintaining a dictionary with term statistics.", "00:07:18": "Document frequency is important for computing IDF which helps match queries with documents.", "00:08:18": "Search engines use indexing and postings to store and retrieve information for efficient search results.", "00:09:18": "Inverted index is used for term matching, including document frequency, postings, and document information.", "00:10:25": "Inverted index stores word positions in documents for faster search of multi-term queries.", "00:11:27": "Inverted index helps answer queries by finding matches and generating scores.", "00:12:28": "Inverted index scores documents for text search engines efficiently with disjunctive queries.", "00:13:29": "Inverted index is faster, as it uses words' distribution in text for quicker searches.", "00:14:29": "Zipf's Law: rank x frequency constant, varied words depending on context.", "00:15:30": "Zipf's law states word frequency and rank have an inverse correlation.", "00:16:31": "Intermediate frequency words are relevant, high frequency words are removed, and rare words exist.", "00:17:35": "Inverted index uses rare words for accurate matching; small dictionary with fast access preferred.", "00:18:39": "Direct access structures efficient for text processing with large dictionary, but difficult with big data.", "00:19:41": "Inverted index postings are compressed to save disk space and improve speed of information retrieval."},
        "Lesson 2.5": {"00:00:00": "Inverted index construction requires specialized methods for large datasets; various methods can solve retrieval issues.", "00:01:00": "Sort tuples by term, build partial index, merge pair-wise to generate inverted index.", "00:02:05": "Converting text to integers simplifies handling, compression, indexing, and retrieval, resulting in more efficiency.", "00:03:07": "Group, sort, and store terms for efficient processing by ID and document in memory.", "00:04:09": "Building an inverted index involves scanning, sorting, and merging documents to efficiently retrieve relevant ones.", "00:05:11": "Inverted indexes compression uses variable length coding and compressed term frequency for large postings.", "00:06:13": "Zipf's law allows for more efficient encoding of document frequency due to non-uniform distribution.", "00:07:15": "\"D-gap compresses large document IDs by storing the difference between adjacent IDs for skewed compression.\"", "00:08:18": "Encoding methods like binary, unary, gamma, and delta require sequential processing for data storage.", "00:09:20": "Unary coding encodes integers with the same number of bits as their value.", "00:10:21": "Importance of decoding variable length encoding methods; avoid aggressive methods for large numbers.", "00:11:24": "Gamma coding compresses data by using unary coding and logarithmic transformation of values.", "00:12:30": "Use uniform code to encode x-2 to log x; unary code for values.", "00:13:32": "Elias Gamma code encodes numbers using unary and binary codes based on logarithmic calculations.", "00:14:35": "Gamma code uses unary and binary coding to represent positive integers with a central 0.", "00:15:36": "Gamma and delta coding are better than unary coding for encoding integers in sorting distributions.", "00:16:38": "Inverted indices compress using methods like gamma coding, unary and gamma for decoding."},
        "Lesson 2.6": {"00:00:00": "Lecture discusses fast research using inverted index and general scoring function, including vector space model.", "00:01:01": "Scoring function in retrieval systems involves adjustments and nested edge function to calculate document score.", "00:02:08": "Algorithm scores documents with function g, h, and an adjustment function using inverted index.", "00:03:10": "Pre-computed factors enhance search efficiency; score accumulator aggregates matching query terms.", "00:04:12": "Inverted indexing efficiently computes document ranking by processing matching documents, updating scores and adjusting rankings.", "00:05:14": "The video explains a basic scoring function for information retrieval using term frequency.", "00:06:14": "Score accumulators start at zero, and scoring equals sum of counts.", "00:07:14": "Inverted index used to find scores for query terms by adding entries and counting occurrences.", "00:08:15": "Keywords tracked to assign scores to documents to rank based on matches using incremental algorithm.", "00:09:20": "Lands normalization is done at document level by processing query terms and checking security.", "00:10:20": "Process rare terms first for more accurate search; weight with pre-computed IDF values.", "00:11:22": "Inverted index uses IDF, caching, and missed result storage for efficient search.", "00:12:22": "Text retrieval systems should use inverted indexes, memory, parallel processing, and distributed storage for efficiency.", "00:13:29": "Lucene has good support, lacking advanced algorithms; Lemur/Indri have advanced algorithms but less support; Terrier has good quotation and some advanced algorithms.", "00:14:32": "Search engines use inverted index, pre-processing, compression and MeTA toolkit for efficient performance.", "00:15:34": "Inverted indexes are efficient. Parallel processing and caching can optimize further."},
        "Lesson 3.1": {"00:00:00": "Evaluation of text retrieval system enhances ranking functions and knowledge improvement.", "00:01:03": "Text retrieval evaluation relies on user judgment to assess system performance and usefulness for developers.", "00:02:04": "Search engine effectiveness can be measured through user studies and test collections to improve systems.", "00:03:07": "Measuring search engine performance involves effectiveness, efficiency, and usability with a focus on accuracy.", "00:04:08": "Cranfield Evaluation Method evaluates text retrieval algorithms developed in the 1960s and still relevant today.", "00:05:12": "Methodology of Info Retrieval involves test collection, defining measures, and relevance judgments for search engines.", "00:06:12": "Information retrieval methodology compares system results to user-ranked lists for fair comparisons and improvement.", "00:07:19": "Users evaluate document relevance for query, compare two system's returned approximations (A and B).", "00:08:21": "Limited or abundant search results: the better search engine depends on user preference and task."},
        "Lesson 3.2": {"00:00:00": "Lecture on evaluating text original systems using test collections to compare and quantify their performance.", "00:01:02": "System A: 2/3 relevant; System B: 3/5 relevant. Measured using matching order precision.", "00:02:05": "System A: high precision. System B: high recall. Both measure search engine performance.", "00:03:08": "Precision and recall evaluate search engines by measuring relevant documents retrieved from a larger set.", "00:04:11": "Calculate precision and recall ratios using the table of relevant and retrieved documents.", "00:05:15": "Precision measures relevant documents retrieved. Recall measures all relevant documents retrieved.", "00:06:16": "Precision measures top relevance, recall measures entire relevance. Both have trade-offs in web search.", "00:07:21": "F measure combines precision and recall using a harmonic mean.", "00:08:24": "F-measure evaluates classification performance based on precision and recall, where F1-measure is a special case.", "00:09:28": "F1 score combines precision and recall and captures their trade-off better than arithmetic mean.", "00:10:28": "Sum of precision and recall unsuitable as measure of search effectiveness; F1 score rewards similarity.", "00:11:29": "Weighted averages emphasize the need to consider appropriate methods for combining data."},
        "Lesson 3.3": {"00:00:00": "Evaluating a ranked list of search results using precision-recall for better quality assurance.", "00:01:01": "Precision-recall is crucial for identifying relevant documents in a ranked list.", "00:02:02": "Precision and recall vary with the number of relevant docs found at different search positions.", "00:03:02": "To measure retrieval accuracy, count relevant and irrelevant documents and estimate if needed.", "00:04:05": "Precision and Average Precision are used to evaluate text retrieval methods, avoiding bias is important.", "00:05:06": "Plot precision-recall curves with precision on y-axis and recall on x-axis using data points.", "00:06:08": "PR curves show precision-recall tradeoff in evaluating retrieval systems, comparing precision between systems.", "00:07:08": "Crossing curves in search system evaluation create difficulty in determining algorithm superiority.", "00:08:10": "Consider user preferences when choosing between search engine algorithms with different capabilities.", "00:09:14": "Choice between retrieval systems depends on user's need for high recall or precision.", "00:10:19": "Precision-recall curve can provide a single measure for performance in decision-making and research.", "00:11:21": "Average precision is used to measure text matching effectiveness by considering recall and precision levels.", "00:12:21": "MAP measures precision in finding relevant documents in information retrieval systems.", "00:13:22": "Precision and recall evaluate ranked lists using relevant documents, with position affecting average precision.", "00:14:23": "Different measures to evaluate search algorithms include Precision at 10 and Mean Average Precision."},
        "Lesson 3.4": {"00:00:00": "Average precision evaluates information retrieval; MAP is the average of average precision over all queries.", "00:01:02": "Discussion on precision, recall, MAP and gMAP measures and their superiority in aggregation.", "00:02:03": "Choosing between MAP and gMAP affects search engine algorithm performance evaluation, rankings and conclusions drawn.", "00:03:05": "Arithmetic mean favours easy queries, gMAP favours difficult ones. Choice depends on user needs.", "00:04:05": "Different methods to retrieve information, pick one that suits best based on context.", "00:05:05": "The reciprocal rank is the average position of a relevant document used in search scenarios.", "00:06:09": "Reciprocal rank measures user effort in finding relevant documents in information retrieval.", "00:07:12": "Ranking with r or 1/r impacts large-scale directories with multiple topics' effectiveness.", "00:08:15": "Reciprocal rank measures relevance of search results, but is less effective for lower ranks."},
        "Lesson 3.5": {"00:00:00": "Text retrieval system evaluated with binding judgments and relevance rating to determine usefulness of pages.", "00:01:01": "New system for search result evaluation based on relevance ratings and gain of top results.", "00:02:03": "NTCG method measures document utility based on relevance and cumulative gain points gained by user.", "00:03:03": "Cumulative gain measures total relevance, while discounted cumulative gain considers rank position.", "00:04:03": "Discounting ranks based on log position, weighing lower-ranked documents less for scoring search results.", "00:05:06": "DCG adjusts rewards for search result position based on topic relevance.", "00:06:10": "DCG rates search engine results by rating documents, calculating scores, and normalizing them.", "00:07:10": "Normalization compares actual to ideal DCG values and maps them to a range of 0-1.", "00:08:13": "Normalization needed for fairness in ranking multiple topics with varying DCG values.", "00:09:16": "NDCG is a relevance measure for ranked tasks that focuses on top k documents."},
        "Lesson 3.6": {"00:00:00": "Evaluating text retrieval systems requires representative test collections with unbiased queries, documents, and relevance judgments.", "00:01:02": "Generating enough data for evaluation in information retrieval is difficult due to limited human labeling.", "00:02:03": "Measuring user utility requires accounting for priorities and statistical testing; accurate results are challenging.", "00:03:08": "Perception of metrics depends on data presentation, thus examine all data points.", "00:04:11": "Statistical tests determine conclusion reliability. Experiment 1 favors A, experiment 2 inconclusive.", "00:05:15": "Varied queries hurt reliability, Sign Test determines system comparison, random results means less reliability.", "00:06:19": "A higher average in coin flips doesn't mean non-randomness; Wilcoxon test and p value needed.", "00:07:22": "Normal distribution used to assess significant difference. Consider probability of random events. 95% range.", "00:08:25": "Statistical tests prevent hasty conclusions; System B was found superior. Judging hard, small data.", "00:09:27": "Pooling selects a subset of relevant documents using diverse ranking methods and combines them.", "00:10:30": "Various ranking methods provide a diverse pool of top-K documents for human judgments with redundancy.", "00:11:32": "Small document pools need new evaluation strategies. Text retrieval is important.", "00:12:36": "User evaluations and the use of specific methods determine the success of ranking algorithms.", "00:13:37": "A-B testing mixes results, user judgement informs determination of the better method. User studies used."},
        "Lesson 4.1": {"00:00:00": "Probabilistic retrieval model treats document and query as random variables introducing relevance variable.", "00:01:00": "Vector space assumes vectors, probabilistic models estimate relevance. Query likelihood and BM25 are effective.", "00:02:02": "PL2 is an effective function in query likelihood, based on probabilistic retrieval models.", "00:03:03": "Users\u2019 clicks determine relevance status of queries and documents in search results.", "00:04:07": "Assessing search result relevance involves estimating probability and collecting data from multiple sources.", "00:05:07": "Calculate probability of observing 1 in third column based on d and q.", "00:06:07": "Probabilistic model ranks documents based on relevant terms occurrence in query and documents.", "00:07:09": "Click-through data improves search engines but is limited by incomplete observations and unseen data.", "00:08:09": "Query Likelihood Model estimates relevance based on conditional probability and user behavior.", "00:09:13": "Conditional probability used to score user queries based on relevant documents via simplified model functions.", "00:10:18": "Relevance is determined by scoring documents based on likelihood of query given document.", "00:11:22": "Ranking function based on query probability given a document using language model in information retrieval."},
        "Lesson 4.2": {"00:00:00": "Introduction to a statistical language model, covering unigram and n-gram models in text retrieval.", "00:01:03": "Language models use probabilities to generate context-dependent phrases with higher likelihoods.", "00:02:05": "Language model generates sequences to account for ambiguity and uncertainty, useful in answering questions.", "00:03:06": "Language models important in speech and text recognition. Unigram model predicts likelihood of word sequence.", "00:04:07": "A simple model for generating text by independently selecting words from a vocabulary distribution.", "00:05:12": "New word model generates one-at-a-time, easier to analyse.", "00:06:16": "Unigram lambda models suggest topics via high probability words. Usage probability affects text likelihood.", "00:07:19": "Certain texts have higher probabilities than others within a given distribution.", "00:08:21": "Estimating word distribution in a document to identify the model used for generating it.", "00:09:23": "Normalization of word frequencies in a document involves maximum likelihood estimation, which has limitations.", "00:10:25": "Including unseen words improves language model; essential for understanding larger texts; useful in various applications.", "00:11:29": "Text representation estimates word frequency in topics, with unique language usage in research papers.", "00:12:29": "Text topic identified by word distribution, computer science related words have higher probabilities.", "00:13:30": "Language models can find related topics and word probabilities, useful for text analysis.", "00:14:31": "Language model eliminates common words for accurate natural language processing, focuses on specific language.", "00:15:32": "Identify computer-related words using probability ratios and lack of occurrence in general contexts.", "00:16:35": "Unigram model used for topic representation, word association and basic semantics analysis. Retrieval function discussed."},
        "Lesson 4.3": {"00:00:07": "Lecture on query likelihood model that generates a query by sampling words from a document.", "00:01:10": "Query formulation involves selecting keywords to develop a retrieval function for search engines.", "00:02:12": "Probabilities of query words are based on relative frequency, assumed to be generated independently.", "00:03:13": "Formula based on keyword frequency used to score and rank documents for information retrieval.", "00:04:18": "Scoring all docs can cause query issues and word order assumptions can be problematic.", "00:05:21": "Zero probability in ranking algorithm causes relevance confusion. Address assumptions to solve the issue.", "00:06:21": "Improved model suggests users use an unigram model to generate queries from an estimated document.", "00:07:22": "Traditional language models have limitations with new words, unique models can solve this with mining.", "00:08:22": "Query likelihood ranks documents based on word independence and probability as the scoring function.", "00:09:26": "To avoid underflow, probabilities are transformed into logarithmic functions and summed for precision.", "00:10:33": "Estimating document relevance to query involves counting words and calculating probability using language model."},
        "Lesson 4.4": {"00:00:07": "Methods for smoothing language models and estimating document language model in probabilistic retrieval.", "00:01:10": "Use Maximum Likelihood Estimate to estimate a language model by normalizing word frequencies.", "00:02:13": "Word frequency determines probability of occurrence. Zero probability for words not found in document.", "00:03:19": "Smoothing assigns probabilities to unseen words, improving accuracy of language models and queries.", "00:04:23": "Language models predict words, but need help with smoothing. Reference models estimate unseen words.", "00:05:26": "Collection Language Model estimates word probability in document based on collection, discounting seen words.", "00:06:29": "Article explains how to apply smoothing formula in query likelihood ranking function.", "00:07:31": "Probability of query term in document calculated using term frequency. Smoothing used for missing terms.", "00:08:33": "Document probabilities split into matched & unmatched query words for sum calculation.", "00:09:33": "Calculation of term frequency. Smoothing assumption affects probabilities. Rewriting sum. Forms of terms.", "00:10:36": "Merging two sums over similar terms simplifies the formula for calculating document probabilities."},
        "Lesson 4.5": {"00:00:00": "Rewriting ranking function helps understand language model. Smoothing, query likelihood, and weighting benefits.", "00:01:02": "Formula for ranking documents updated to only sum matching query terms, ignoring last term.", "00:02:07": "Frequency used in vector space model query relates to TF-IDF weighting of document vector.", "00:03:08": "Combined formula for scoring includes TF, IDF, length normalization, and popularity reflected in denominator.", "00:04:14": "Term relates to IDF weighting & document length normalization; penalizes long docs for being larger.", "00:05:18": "Language model smoothing penalizes long documents and uses a fixed ranking function.", "00:06:23": "Logarithms improve scoring efficiency in probabilistic models but not needed for TF and IDF weighting.", "00:07:24": "Smoothing improves models by reducing zero probabilities and using connection language model for unseen words.", "00:08:26": "Query likelihood formula combines weighting, length normalization, and requires smoother and reference language."},
        "Lesson 4.6": {"00:00:00": "Lecture covers smoothing in language models for query likelihood ranking in probabilistic retrieval model.", "00:01:00": "Two smoothing methods for Jelinek-Mercer function: linear interpolation and Dirichlet smoothing; lecture explains details.", "00:02:04": "Estimation of language model using maximum likelihood method and smoothing for non-observed words.", "00:03:05": "Laplacian smoothing avoids zero probability by adding a small value to network words.", "00:04:05": "Language models face zero probability issues, solved by add-one or Bayesian/Dirichlet smoothing using hyperparameter alpha.", "00:05:05": "Formula combines maximum and collection language models with dynamic coefficient for more sensible smoothing.", "00:06:05": "Smoothing formula uses dynamic coefficients to ensure normalisation of counts and probabilities.", "00:07:10": "Adding pseudo counts with parameter mu adjusts word probabilities for accurate estimation.", "00:08:13": "Pseudocounts add to LM to handle unseen words, represented by alpha sub d."},
        "Lesson 4.7": {"00:00:00": "JM method smooths data using model masses, ranking functions based on D, pc values, and ratio.", "00:01:00": "Text explains a probability-based ranking function for search engine optimization independent of the document.", "00:02:02": "The vector space model uses heuristics to match query terms with documents' relevance.", "00:03:04": "Language modeling generates weighting function based on assumptions with denominator as expected frequency.", "00:04:08": "Dirichlet Prior Smoothing uses ratios to compare actual and expected word counts for document ranking.", "00:05:11": "Jelinek-Mercer and Dirichlet priors are different smoothing techniques used in Natural Language Processing.", "00:06:15": "Docking lens in alpha sub-d scores document vectors through adjustments based on document.", "00:07:15": "TF-IDF and normalization weigh word frequency, but may not always be effective or have drawbacks.", "00:08:17": "Risk model changes can have unpredictable consequences, but competitiveness remains important.", "00:09:21": "Risk models' improvement over PM2.5 with Jelinek-Mercer and Dirichlet Prior smoothing methods, but unclear consistency.", "00:10:23": "Probabilistic model uses TF-IDF weighting and smoothing parameters, with similar results to vector space model.", "00:11:24": "Query likelihood model: relevance determined by query, independence of words, unseen words assumed, smoothing used."},
        "Lesson 5.1": {"00:00:00": "User evaluates usefulness of search results in Feedback in Text Retrieval after inputting query.", "00:01:00": "Relevance Feedback seeks user input to improve search accuracy, while Pseudo Feedback uses top-ranked results.", "00:02:00": "Blind feedback assumes top-ranked documents are relevant, improves search results without user input.", "00:03:03": "Word association finds related terms to a query by analyzing frequent words in search results.", "00:04:04": "Observing user interaction with search results for improving search relevance, without asking for judgments.", "00:05:06": "Feedback (explicit, implicit, inferred) helps search engines (Google, Bing) improve relevant results."},
        "Lesson 5.2": {"00:00:00": "Feedback in vector space model involves modifying query vector through positive and negative examples.", "00:01:03": "Query expansion enhances accuracy via weight modification and adding terms, with Rocchio feedback most effective.", "00:02:03": "Find relevant docs using a query and similarity function, adjust query position to improve accuracy.", "00:03:05": "Rocchio's method adjusts the query towards relevant documents and away from negative ones' centroid.", "00:04:06": "Query expansion improves relevance by moving towards relevant documents and using centroid vector algebra.", "00:05:13": "Rocchio Feedback creates a new query vector from relevant and non-relevant centroid vectors.", "00:06:15": "Rocchio method computes centroids for positive and negative documents, including nested documents.", "00:07:18": "Rocchio feedback method improves queries by combining query vector with positive and negative centroid vectors.", "00:08:22": "Refining retrieval vector with feedback adjusts query by identifying relevance and truncating non-relevant terms.", "00:09:27": "Centroid method truncates vectors for faster and more useful results in difficult queries.", "00:10:30": "Keep high weight on original query terms to prevent over-trusting feedback and drifting."},
        "Lesson 5.3": {"00:00:00": "Language model feedback approach limitations, query likelihood, unnatural sampling of feedback words.", "00:01:03": "KL divergence generalizes query likelihood for feedback and vector space similarity.", "00:02:05": "KL-divergence model measures difference between user's query and language model, estimated using feedback information.", "00:03:07": "Cross entropy formula and KL-divergence function used to match query words in natural language processing.", "00:04:09": "KL-divergence is a model used in feedback to estimate document and query language models' difference.", "00:05:14": "Rocchio - query & feedback docs; LM - document vector; Feedback model - interpolation.", "00:06:14": "Generative mixture approach using relevant documents can create a user feedback model.", "00:07:17": "Language model normalizes word frequency, but common words should be removed for better feedback.", "00:08:17": "Assign high probabilities to common non-relevant words using a background language model.", "00:09:19": "Use source controller that selects model to reduce word probability; background model is not ideal.", "00:10:20": "Mixture model generates words randomly and analyses text with lambda parameter determining distribution.", "00:11:20": "Max likelihood estimator adjusts mixture models by explaining all data using a background model.", "00:12:23": "Impossible to summarize as it explains the absence of information.", "00:13:24": "Topic model for feedback with weight to remove top words and noise parameter.", "00:14:25": "Pseudo-feedback model adapts to user search needs using probability distributions and feedback.", "00:15:25": "Feedback model suggests relevant words to improve document retrieval accuracy, aiding airport security.", "00:16:26": "Lambda values affect common words and background models in a topped model for text generation.", "00:17:28": "Language models use feedback to learn from examples, including relevance feedback, pseudo-feedback, and implicit feedback."},
        "Lesson 5.4": {"00:00:07": "Web search engines face challenges in scalability, completeness, speed, and coverage of information.", "00:01:07": "Web search engines face challenges like spam, scale, and dynamic pages, but links improve results.", "00:02:11": "Web search techniques developed for scalability, spam detection, robust ranking, and leveraging page linking.", "00:03:15": "Search engines crawl, index and retrieve information to improve web search results for users.", "00:04:19": "Web search involves crawling, collecting data, adding links, and showing results to users for interaction.", "00:05:19": "Crawling must consider server load, file types, duplicates, exclusion, hidden URLs, and JavaScripts.", "00:06:19": "Search engine crawling includes breadth-first, parallel and focused strategies for accessing new pages.", "00:07:25": "Challenges in web crawling: finding new pages, updating links, and efficient crawling of updated pages.", "00:08:27": "Frequency and extent of updates and traffic drive web crawling requirements for dynamic content.", "00:09:31": "Web search needs fresh pages, efficient crawlers, quality information. Complete or focused crawling required."},
        "Lesson 5.5": {"00:00:00": "Creating web-scale index involves an indexer inverted indexing crawled web pages to enhance efficiency.", "00:01:00": "Google made GFS and MapReduce for big data. Hadoop is open source version.", "00:02:01": "GFS efficiently stores and locates files using namespace, lookup table, and chunking on multiple machines.", "00:03:01": "Google file system: 64MB chunks, efficient transfer, MapReduce for parallel programming.", "00:04:05": "MapReduce simplifies parallelization, distribution, and fault tolerance across large clusters for efficient data processing.", "00:05:05": "MapReduce partitions data for parallel processing, with a framework that automates task dispatch.", "00:06:05": "MapReduce processes big data by mapping, sorting and reducing in a distributed manner.", "00:07:10": "MapReduce is a framework for parallel processing and simplifying programming with map and reduce functions.", "00:08:10": "MapReduce parallelizes word count for assessing popularity in large collections by dividing and combining counts.", "00:09:12": "Map function counts words in each line of text by key-value pairs and Collect function.", "00:10:14": "MapReduce processes data efficiently by mapping, collecting, sorting, and producing key-value pairs with word counts.", "00:11:20": "MapReduce divides large data for parallel processing through Map and Reduce operations.", "00:12:21": "Map function groups word counts and document IDs for inverted index creation in parallel.", "00:13:27": "Map function identifies document IDs, reduce groups them by key, produces inverted index entry.", "00:14:27": "Inverted index construction involves mapping and reducing data to create consolidated info using MapReduce.", "00:15:32": "MapReduce in Hadoop creates large-scale inverted index with parallel processing for web search."},
        "Lesson 5.6": {"00:00:00": "Link analysis important for web search, building on indexing to address varied information needs.", "00:01:02": "Navigational queries require targeted page finding on web with link information and scoring algorithm.", "00:02:03": "Multiple signals in ranking algorithms prevent spamming. Features include links, clickthroughs, and queried iCode.", "00:03:07": "Links and anchor text provide scoring signals for search engines and give extra page descriptions.", "00:04:07": "Anchor text is crucial for ranking and relevance; it helps search engines identify pages.", "00:05:08": "Authority pages have inbound links, while hub pages have outbound links.", "00:06:09": "Page rank algorithm scores links to measure authority and popularity using direct and indirect links.", "00:07:13": "PageRank algorithm considers quantity and quality of direct and indirect links to determine webpage ranking.", "00:08:13": "PageRank measures importance of webpages through virtual links and pseudo citation count using linear algebra."},
        "Lesson 5.7": {"00:00:00": "The random surfing model allows surfer to access any page and follow links randomly.", "00:01:06": "Links to D3 and D4. Surfer may randomly jump to any page on web.", "00:02:06": "Servers can access website pages not directly linked to by randomly navigating the site.", "00:03:07": "Google's algorithm calculates the likelihood of a page being visited based on in-links.", "00:04:11": "Transition matrix used to determine likelihood of movement between web pages for capturing links.", "00:05:14": "Matrix predicts webpage visits by showing probability of moving between pages to find target page.", "00:06:18": "PageRank scores pages based on links, considering link probability vs. random surfing.", "00:07:23": "PageRank algorithm measures web page importance through probability of random surfer landing on page.", "00:08:28": "PageRank smooths transition probabilities to avoid zero entries and calculate page relevance.", "00:09:29": "Solve N linear equations with N variables to obtain vector P for webpage probability.", "00:10:30": "Algorithm uses matrix multiplication to calculate webpage importance, updated iteratively for better accuracy.", "00:11:32": "Using transition metrics and interpolation to create virtual links for comprehensive PageRank computation.", "00:12:37": "Page ranking involves metric multiplication and iterative updating of scores to achieve convergence.", "00:13:38": "PageRank converges by propagating scores on the graph and updating values using a formula.", "00:14:38": "PageRank assigns importance to web pages using matrix multiplication and a damping factor.", "00:15:43": "Google's PageRank algorithm ranks web pages based on link quality/quantity. Can include topic-specific score."},
        "Lesson 5.8": {"00:00:00": "HITS algorithm scores authority and hub pages based on mutual citations to improve their scoring.", "00:01:04": "Hub pages link to authority pages to increase relevance and value using the Hub-and-Authority algorithm.", "00:02:08": "Hub and authority scores defined by two equations, determined by pages pointing to each other.", "00:03:11": "Explanation of hubs/authorities and their relation to eigenvectors/matrix algebra in network analysis.", "00:04:11": "HITS algorithm uses two matrices and link information to calculate hub and authority scores."},
        "Lesson 6.1": {"00:00:00": "Machine learning combines features to optimize web search results using content and link-based scoring models.", "00:01:03": "Machine learning improves web page ranking accuracy and robustness, making it harder for spammers.", "00:02:04": "Anchor text, URL, and query commands determine relevance and create a ranking function.", "00:03:07": "Search query relevance depends on features with varying weight, determined through empirical evaluation.", "00:04:08": "Relevance judgments optimize retrieval accuracy through user feedback, adjusting parameters, and prioritizing important features."},
        "Lesson 6.2": {"00:00:00": "Regression assumes relevance is related to linear combination of features; features summed linearly.", "00:01:03": "Scoring function combines features with weighting parameters and transforms probability of relevance.", "00:02:05": "The probability of relevance is determined by a linear combination of coefficients and features.", "00:03:12": "Hypothesis suggests a combination function to determine document relevance, beta values needed for estimation.", "00:04:15": "Improving search results using feature values and maximum likelihood estimator based on relevance judgments.", "00:05:18": "Function predicts document relevance based on feature values, determined by beta values.", "00:06:21": "Probability of document relevance expressed as 1 or 0 using necessary feature values.", "00:07:28": "Model predicts document relevance, maximizing probability crucial for random documents.", "00:08:29": "Adjust beta values to maximize probability by minimizing the second part of the formula."},
        "Lesson 6.3": {"00:00:00": "MAP and nDCG better than regression for retrieval optimization. Regression not effective for ranking.", "00:01:03": "Learning-to-rank approaches prioritize ranking order over other factors in document retrieval and beyond.", "00:02:03": "Machine learning is used in information retrieval with large amounts of training data and features.", "00:03:04": "Data and machine learning improve rankings and combat spam in search engines. Active research."},
        "Lesson 6.4": {"00:00:00": "Vertical search engines improve accuracy by catering to users' common information needs based on groups.", "00:01:02": "Customized search engines improve document understanding and personalization, leading to continuous development and intelligent search.", "00:02:03": "Personalized search, user feedback, and integrated systems shape future information access and management.", "00:03:05": "Future info systems to support multi-mode access and purchasing workflows beyond searches.", "00:04:09": "GPT-3 needs improvements in literature search and academic writing. Suggestions for intelligent information systems.", "00:05:09": "The Data-User-Service Triangle determines system function based on users, data, and service types.", "00:06:12": "Connect science & literature for new info & connect shoppers to reviews & analysis.", "00:07:15": "System analyzes emails for complaints, generates responses and promotions to improve customer service productivity.", "00:08:19": "Technology advances towards smarter systems for better search, user comprehension and information interpretation.", "00:09:24": "Google uses NLP, user modelling, and entity relations to create personalized intelligent systems.", "00:10:24": "Semantic analysis improves search engines, summarization is essential. Recommender systems aid the process.", "00:11:25": "Smart systems process data, turn text into actions, enhance efficiency via human input."},
        "Lesson 6.5": {"00:00:00": "This lecture explains recommender systems, search engines, ranking problems, and evaluation methods for search engines.", "00:01:01": "Recommender systems recommend relevant information in push mode for stable information needs like filters.", "00:02:05": "Filtering systems deliver relevant content based on user interests and dynamic sources/preferences.", "00:03:11": "Content-based and collaborative filtering are two recommender system strategies based on item or user similarity.", "00:04:13": "IR system uses classification and learning to adjust recommendations based on user feedback and interests.", "00:05:16": "Filtering system improves classifier performance using linear utility function for real-time decision-making.", "00:06:17": "Treating article delivery as a gambling game to maximize earnings is unclear and requires analysis.", "00:07:20": "Threshold utility function choice impacts system behavior; appropriate weighting essential for incentivizing quality outcomes.", "00:08:22": "Content-based filtering relies on accurate utility function, with challenges in decision and initialization modules.", "00:09:23": "For effective filtering, user model, document model, and learning module are necessary.", "00:10:26": "Filtering information by scoring documents against queries using feedback techniques to improve scoring.", "00:11:27": "Filtering email requires updating the threshold over time with a scoring module and user feedback."},
        "Lesson 6.6": {"00:00:00": "Filtering problem involves biased data and few labeled examples, making learning difficult.", "00:01:03": "Challenge of building document recommendation with limited data and balancing exploration with user preferences.", "00:02:07": "Balancing exploration and exploitation in personalized content recommendations with empirical utility optimization for optimal results.", "00:03:09": "Estimate optimal ad score threshold on training data by accounting for exploration and bias.", "00:04:13": "Lowering threshold for exploration with beta-gamma approach improves personalized recommendations and avoids discarding items.", "00:05:17": "Lowering the utility threshold enables exploration at a safe point between optimal utility and zero.", "00:06:22": "Encourage threshold mechanism, use beta for deviation, gamma for over-training to define alpha.", "00:07:24": "The gamma formula determines exploration level based on number of training examples.", "00:08:25": "A heuristic approach for reinforcement learning with a lower bound for exploration-exploitation tradeoff.", "00:09:26": "Recommendation systems use content-based and collaborative filtering strategies with search engines as the base."},
        "Lesson 6.7": {"00:00:00": "Collaborative filtering uses similar user preferences to make recommendations in recommender systems.", "00:01:01": "Predict preferences by analyzing similar users' shared interests, assuming similar preferences and interests.", "00:02:03": "Assumptions in collaborative filtering: predicting user interests based on similarity and available data.", "00:03:03": "Collaborative filtering suggests items based on ratings, but faces a problem with little data.", "00:04:05": "Collaborative filtering is using observed ratings to predict unknown ratings for items.", "00:05:09": "Predicting function values through observed data for recommendation systems is an active research area."},
        "Lesson 6.8": {"00:00:00": "Predict user ratings by finding similar users and using their ratings to predict preferences.", "00:01:05": "Normalization of ratings involves subtracting average ratings to make them comparable due to user bias.", "00:02:08": "Recommendation systems predict user preference based on behavior and normalize ratings for accurate predictions.", "00:03:13": "Weights in collaborative filtering determine user similarity and influence on predicted preferences.", "00:04:13": "Normalizing user ratings and measuring similarity requires a normalizer variable \"k\" for consistent weighting.", "00:05:14": "Memory-based CF predicts user rating, normalizes it for recommendation, adjusts for user bias.", "00:06:17": "Collaborative filtering assumes unknown ratings and memory-based approaches face difficulty in determining 'w'.", "00:07:22": "CF weight computed by Pearson Correlation or cosine measure, based on similarity of rating patterns.", "00:08:23": "Collaborative filtering recommends based on similar user preferences without considering item content.", "00:09:24": "Collaborative and content-based filtering combine, but missing values and user similarity need improvement for accuracy.", "00:10:26": "Collaborative filtering predicts recommendations by finding similarity in user preferences and filling missing data."},
        "Lesson 6.9": {"00:00:00": "Recommender systems offer suggestions, but filtering useful content quickly is a challenge.", "00:01:00": "Recommender systems face challenges like data sparseness, diversity and decision making difficulty, but solutions exist.", "00:02:00": "Solve inaccurate recommendations using hybrid strategies, user information, content-based, and push mode.", "00:03:02": "Research aims to improve search engine usability by incorporating context information and social networks."},
        "Lesson 6.10": {"00:00:00": "Complex search requires deeper processing in natural language content analysis than current NLP methods.", "00:01:01": "Discussion on text access strategies, push/pull methods, search engines, and effective model retrieval functions.", "00:02:02": "Text retrieval systems create indexes to answer queries quickly using heuristics, evaluated by Cranfield.", "00:03:05": "Search engine improves with feedback, indexing, link analysis, and measures like MAP and nDCG.", "00:04:06": "\"Rank learning improves search with feature combination, spam prevention; recommender systems use filtering.\"", "00:05:06": "Search engine UI important, recommended book on studies, advanced topics for text retrieval.", "00:06:09": "Synthesis Digital Library & other resources provide comprehensive coverage of the course's topics.", "00:07:09": "Course covers text retrieval, human involvement for converting raw data to relevant application.", "00:08:13": "Text mining courses aid in data analysis to improve decision-making and task completion through insights."}
    }
}